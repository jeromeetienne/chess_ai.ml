# TODO
- use that everywhere    class FILE_SUFFIX:
        BOARDS = "_boards_tensor.pt"
        MOVES = "_moves_tensor.pt"
        EVALS = "_evals_tensor.pt" 
- do a regression in a corner 
  - it should not have the same issue that the classification with 1972 classes
  - https://gemini.google.com/app/b8047920ab1f4b67
  - `tmp/regression.py`
- do a multi head model in a corner to see how it goes
  - perplexity - https://www.perplexity.ai/search/explain-mcts-in-machine-ai-to-BwJw_pPYTL6nU8Y5KPN.Mg
- do a bench of inference - thus i can compare the model inference speed
- multi-head network: good for alpha alpha-zero 
  - mcts + 2 models (one to pick the best move during mcts, one to evaluate the board on the leaf nodes)
  - see PUCT (mcts + nn) vs UCT (mcts only)
- in the model, 
  - add Global Average Pooling (GAP), maybe a MaxPool2d after the conv layers - https://gemini.google.com/app/cdfdec954e81eaff
  - add a dropout layer only after fully connected layer
  - code model with self.fc_layers = nn.Sequential() pattern https://chatgpt.com/c/68de57d9-67f0-832b-aebb-c8d110effe48
- how many chess move are there ?
  - https://www.chess.com/blog/the_real_greco/another-silly-question-how-many-chess-moves-are-there
- https://www.informatik.tu-darmstadt.de/fb20/aktuelles_fb20/fb20_news/news_fb20_details_308928.en.jsp
- understand the alpha zero paper move encoding
  - perplexity summarizing it - https://www.perplexity.ai/search/how-alpha-zero-encode-chess-mo-RbG7COYhRFqvorVml7IRGA
  - [gym chess move encoding](https://github.com/iamlucaswolf/gym-chess/blob/master/gym_chess/alphazero/move_encoding/)
- make a small script which compute the list of all move type at chess
  - https://gemini.google.com/app/b876c2f17d4fde4e
  - https://www.chess.com/blog/the_real_greco/why-is-the-queen-strongest-answering-two-silly-questions
  - https://www.chess.com/blog/the_real_greco/move-finding-the-engine-way
  - https://www.chess.com/blog/the_real_greco/another-silly-question-how-many-chess-moves-are-there
  - AI seems to contradict the alpha zero paper which says there are 4672 possible moves
  - brute force all possible moves on an empty board
- code a way to train on a special range of moves, not the whole game
  - select by move number (e.g. 10 to 30)
  - later by dynamically detecting opening, midgame, endgame
  - generate multiple dataset files for each stage of the game
- make it play on lichess ?

# DONE
- DONE use this pgn... it has the position from stockfish and its evaluation
  - keep the folders structure to keep track of the source
  - https://huggingface.co/datasets/official-stockfish/fishtest_pgns
  - read it thru the usual build_dataset.py
  - do a special `build_evals.py` for it
  - `build_evals_stockfish.py`
  - `build_evals_fishtest.py`
- DONE change the encoding to be always from the point of view of the side to play
  - active side vs opponent side
- WONTDO create a model which has only white turn
  - and another for black turn
  - NOTE: would allow to know how much better the model would be if it see only one side of the board
- DONE create a new class called encoding.py with a unit test, and then use it everywhere in the code
  - in encoding, if turn is black, flip the board so that always the side to play is at the bottom
  - it will make learning easier
  - do that for board and for move (e2e4 becomes e7e5 ?)
- DONE see if you can create a `eval_tensor` which is the stockfish evaluation of the `board_tensor`
  - thus i can learn a model which evaluates the board, on top of the one which suggest the best move
  - those are the 2 models in alpha zero
  - FIXME: issue in the `board_from_tensor` function. see script in `./tmp/dataset_to_eval.py`
- DONE finish the boards tensor to eval script
  - it is a good checker
- WONTDO using gym_chess to generate the board mapping
  - save it in a file, then the uci2class is static
  - check with your own list of all possible moves (you are missing 4 moves)
  - no need to have uci_to_classindex everywhere
  - thus i can encode all the dataset once and for all
  - for all position in the dataset, i store 
    - the next move which has been player
    - the board tensor
    - the eval tensor
  - **TO FLIP A MOVE**: get the class index to UCI, parse row/col, flip row/col 7-row, 7-col, convert back to UCI, convert back to class index
  - as in this function [Move.rotate](https://github.com/iamlucaswolf/gym-chess/blob/master/gym_chess/alphazero/move_encoding/utils.py#L34) in gym-chess
  - move_pack(uci) -> chess.Move
  - move_unpack(chess.Move) -> uci
  - move_flip(chess.Move) -> chess.Move
- DONE can i encode the move flip by changing the mapping ?
  - one mapping if it is white to play, another if it is black to play
  - and you store both mapping in the dataset
  - easy and backward compatible
  - `uci2class.mapping[turn]` 
  - `uci2class.num_classes`
- DONE fix the bug in the board encoding
  - https://github.com/iamlucaswolf/gym-chess/blob/master/gym_chess/alphazero/board_encoding.py
  - encode every as alpha-zero as it is the FEN standard
  - except the 14 previous moves, encode only the last move
  - encode all this thru constants - it will keep the information in the source
- DONE make a converter .pgn to the dataset format for each file
  - PRO it would avoid the 'build_dataset' step during training (which can take 10+ minutes for large pgn files)
  - thus you can reload the dataset without reprocessing the pgn files
  - Q. how to handle `uci_to_classindex` changes ? would work if i have it static (./bin/all_possible_moves.py)
- DONE have a tool to go from boards to tenser and back
  - `board_to_tensor(board) -> tensor`
  - `tensor_to_board(tensor) -> board`
- WONTDO generalize the game slice in the dataset builder
  - allow not to set begining and end move_index
  1. build a dataset for each stage of the game (opening, midgame, endgame)
  2. train a model for each stage of the game
  3. during play, detect the stage of the game and use the corresponding model
- DONE try to train on the stockfish pgn
- DONE do a pgn splitter
  - will be used for large pgn files - stockfish or lichess
  - `{original_basename}_{N}_on_{total}.pgn`
  - pgn_splitter.py -mgp 200 *.pgn
    - --max-games <int> : maximum number of games per output file (default: 1000)
  - be efficient when scanning the pgn file
    - first pass: count the number of games, and the byte offset of each game
    - second pass: write the games to the output files
- DONE look for model structure on the web
  - search for 'pytorch chess model'
  - search for 'pytorch chess neural network'
  - search for 'pytorch/tensorflow alpha zero github'
- DONE check_dataset: go thru all the board in the dataset and check it is equal to the pgn
  - compare fen by string
  - display evaluation too
  - allow to specify a game + move index - would help push it in chess.com
- DONE whem building dataset, drop position which are in the opening phase
- DONE experiment with the attacked squares feature
  - https://python-chess.readthedocs.io/en/latest/core.html#chess.Board.attacks
  - add it to the input tensor
  - see if it improves the model
- DONE organize `./libs`
- DONE the type used in input/output is a mess. Sometimes float32, sometimes long
  - search for ".float" or ".long" or ".int"
  - centralize it and then set it 
  - best setting: likely int8 for input, and int16 for output
- DONE read opening books
  - here are some pgn https://sites.google.com/site/computerschess/download
  - more polyglot opening books https://github.com/michaeldv/donna_opening_books/
  - several collection https://chess.stackexchange.com/questions/35448/looking-for-polyglot-opening-books
  - how to use it https://chess.stackexchange.com/questions/24738/how-to-use-opening-books-on-mac-linux
- DONE implement better looking board display - between ascii art and color - it is possible to do something more readable
  - https://rebel13.nl/download/books.html
- WONTDO plug stockfish into python chess
  - https://python-chess.readthedocs.io/en/latest/engine.html
- DONE do early stopping during training
- DONE evaluate the model on a validation set during training
- DONE add proper logs in `./train.py` and `./predict.py`
- DONE connect `./play.py` to lichess.org to play online
  - add it in `Makefile`
- DONE in `./train.py`, save the model every N epochs
- DONE do a `./play.py` able to play against a human and stockfish, with good cmdline args
  - cmdline options:
    - `--model-path` to load a model
    - `--engine-path` to load a chess engine (stockfish)
    - `--time` time per move for the engine
    - `--color` white or black for the ml bot
  - display the board in ascii
  - move in uci format (e2e4)
  - display the move suggested by the model and the move suggested by stockfish
- DONE in `./train.py`, cache the dataset in numpy format for faster loading
- DONE clean up `./train.py` and `./predict.py`
- DONE rename X to `board_tensor`, y to `move_tensor`
  - or `input_tensors`, `expected_target_tensors`
- DONE rename `move_to_int` to `uci_to_classindex`
- DONE that a test dataset is separate from the training dataset
- DONE display chess board with unicode characters
